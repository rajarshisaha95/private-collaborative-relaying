{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9a802e-bd76-4827-b493-d3256219d775",
   "metadata": {},
   "source": [
    "This script tests the weight optimization procedure of ColRel using gradient descent based optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5cfb52-f1b1-43d3-9b5e-b05a866f42ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423eb223-5cb1-4399-a87f-f38d3aa9474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmWave network topology definition\n",
    "\n",
    "def client_locations_mmWave_clusters_intermittent(num_clients: int = 10):\n",
    "    \"\"\"\n",
    "    :param num_clients: Number of federated edge learning clients\n",
    "    :return: probability of successful transmission to PS, and inter-client connectivity matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # PS is placed at origin\n",
    "    PS_loc = np.array([0, 0])\n",
    "\n",
    "    # Distance of good clients from PS\n",
    "    circle_good_rad = 159                       # meters. For prob success ~ 0.9\n",
    "\n",
    "    # Clients angles\n",
    "    client_vec_deg = np.zeros(num_clients)\n",
    "    client_vec_deg[3] = 2 * np.pi / 3\n",
    "    client_vec_deg[6] = 4 * np.pi / 3\n",
    "\n",
    "    x = np.zeros(num_clients)\n",
    "    y = np.zeros(num_clients)\n",
    "\n",
    "    # Determining the Cartesian coordinates of the clients with good connectivity\n",
    "    x[0] = circle_good_rad * np.cos(client_vec_deg[0])\n",
    "    y[0] = circle_good_rad * np.sin(client_vec_deg[0])\n",
    "    x[3] = circle_good_rad * np.cos(client_vec_deg[3])\n",
    "    y[3] = circle_good_rad * np.sin(client_vec_deg[3])\n",
    "    x[6] = circle_good_rad * np.cos(client_vec_deg[6])\n",
    "    y[6] = circle_good_rad * np.sin(client_vec_deg[6])\n",
    "\n",
    "    d = 159                       # Distance of bad clients in each cluster to the good client of the cluster\n",
    "\n",
    "    # Cluster 1\n",
    "    ang1 = 1.582\n",
    "    x[1] = x[0] + d * np.cos(ang1)\n",
    "    y[1] = y[0] + d * np.sin(ang1)\n",
    "    print(\"Distance = {}\".format(np.sqrt(x[1] ** 2 + y[1] ** 2)))\n",
    "\n",
    "    ang2 = - 1.582\n",
    "    x[2] = x[0] + d * np.cos(ang2)\n",
    "    y[2] = y[0] + d * np.sin(ang2)\n",
    "\n",
    "    # Cluster 2\n",
    "    ang4 = 2 * np.pi / 3 + 1.582\n",
    "    x[4] = x[3] + d * np.cos(ang4)\n",
    "    y[4] = y[3] + d * np.sin(ang4)\n",
    "\n",
    "    ang5 = 2 * np.pi / 3 - 1.582\n",
    "    x[5] = x[3] + d * np.cos(ang5)\n",
    "    y[5] = y[3] + d * np.sin(ang5)\n",
    "\n",
    "    # Cluster 3\n",
    "    ang7 = 4 * np.pi / 3 - 1.582\n",
    "    x[7] = x[6] + d * np.cos(ang7)\n",
    "    y[7] = y[6] + d * np.sin(ang7)\n",
    "\n",
    "    ang8 = 4 * np.pi / 3 - 1.54\n",
    "    x[8] = x[6] + d * np.cos(ang8)\n",
    "    y[8] = y[6] + d * np.sin(ang8)\n",
    "\n",
    "    ang9 = 4 * np.pi / 3 + 1.582\n",
    "    x[9] = x[6] + d * np.cos(ang9)\n",
    "    y[9] = y[6] + d * np.sin(ang9)\n",
    "\n",
    "    # Client locations\n",
    "    loc_clients = []\n",
    "    for idx in range(num_clients):\n",
    "        loc_clients.append([x[idx], y[idx]])\n",
    "    loc_clients = np.array(loc_clients)\n",
    "\n",
    "    # Compute distances of clients from PS\n",
    "    sub_clients_PS = loc_clients - PS_loc\n",
    "    dist_clients_PS2 = np.zeros(len(sub_clients_PS))\n",
    "    for idx in range(len(sub_clients_PS)):\n",
    "        dist_clients_PS2[idx] = sub_clients_PS[idx][0] ** 2 + sub_clients_PS[idx][1] ** 2\n",
    "    dist_clients_PS = np.sqrt(dist_clients_PS2)\n",
    "\n",
    "    # Compute pairwise distances between clients\n",
    "    dist_clients_clients = np.zeros([num_clients, num_clients])\n",
    "    for i in range(len(loc_clients)):\n",
    "        for j in range(len(loc_clients)):\n",
    "            dist_vector = loc_clients[i] - loc_clients[j]\n",
    "            dist_clients_clients[i][j] = np.linalg.norm(dist_vector, 2)\n",
    "\n",
    "    # Compute probability of successful transmission to PS\n",
    "    prob_success_PS = np.zeros(num_clients)\n",
    "    for i in range(len(dist_clients_PS)):\n",
    "        p = min(1, np.exp(-dist_clients_PS[i] / 30 + 5.2))\n",
    "        prob_success_PS[i] = np.round(p * 100) / 100\n",
    "\n",
    "    # Determine connectivity amongst clients\n",
    "    P = np.zeros([num_clients, num_clients])\n",
    "    connectivity_mat_clients = np.zeros([num_clients, num_clients])\n",
    "    for i in range(num_clients):\n",
    "        for j in range(num_clients):\n",
    "            p = min(1, np.exp(-dist_clients_clients[i][j] / 30 + 5.2))\n",
    "            if p > 0.5:\n",
    "                P[i][j] = p\n",
    "                connectivity_mat_clients[i][j] = 1\n",
    "\n",
    "    with open('prob_success_PS.npy', 'wb') as f:\n",
    "        np.save(f, prob_success_PS)\n",
    "    with open('connectivity_mat_clients.npy', 'wb') as f:\n",
    "        np.save(f, connectivity_mat_clients)\n",
    "\n",
    "    return prob_success_PS, P, connectivity_mat_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c3cf9-40ed-43b0-a05d-72c841535c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Topology induce variance\n",
    "\n",
    "def evaluate_tiv(p: torch.Tensor = None, A: torch.Tensor = None, P: torch.Tensor = None):\n",
    "    \"\"\"Evaluate the upper bound on topology induced variance\n",
    "        :param p: Array of transmission probabilities from each of the clients to the PS.\n",
    "        :param A: Matrix of weights\n",
    "        :param P: Matrix of probabilities for intermittent connectivity amongst clients\n",
    "    \"\"\"\n",
    "    \n",
    "    num_clients = len(p)\n",
    "    A_dim = A.shape\n",
    "    neighbors_dim = P.shape\n",
    "    \n",
    "    # Validate inputs\n",
    "    assert num_clients == A_dim[0] == A_dim[1]\n",
    "    assert num_clients == neighbors_dim[0] == neighbors_dim[1]\n",
    "    \n",
    "    # First term\n",
    "    S = 0\n",
    "\n",
    "    # First term\n",
    "    for i in range(num_clients):\n",
    "        for l in range(num_clients):\n",
    "            for j in range(num_clients):\n",
    "                S += p[j] * (1 - p[j]) * P[i][j] * P[l][j] * A[i][j] * A[l][j]\n",
    "\n",
    "    # Second term\n",
    "    for i in range(num_clients):\n",
    "        for j in range(num_clients):\n",
    "            S += P[i][j] * p[j] * (1 - P[i][j]) * A[i][j] * A[i][j]\n",
    "\n",
    "    # Third term\n",
    "    for i in range(num_clients):\n",
    "        for l in range(num_clients):\n",
    "            assert P[i][l] == P[l][i], \"Matrix P must be symmetric.\"\n",
    "            E = P[i][l]\n",
    "            S += p[i] * p[l] * (E - P[i][l] * P[l][i]) * A[l][i] * A[i][l]\n",
    "            \n",
    "    # Compute the bias terms\n",
    "    s = torch.zeros(num_clients)\n",
    "    for i in range(num_clients):\n",
    "        for j in range(num_clients):\n",
    "            s[i] += p[j] * P[i][j] * A[i][j]\n",
    "            \n",
    "    # Contribution of the term due to bias\n",
    "    for i in range(num_clients):\n",
    "        for j in range(num_clients):\n",
    "            S += (s[i]*s[j] - 2*s[i] + 1)\n",
    "\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f9531-864c-407e-bec3-4453a3444c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization to control bias\n",
    "\n",
    "def evaluate_regularizer(p: torch.Tensor = None, A: torch.Tensor = None, P: torch.Tensor = None, \n",
    "                         reg_type: str = \"L2\", reg_strength: torch.Tensor = torch.tensor(0)):\n",
    "    \"\"\"Evaluate the regularization term\n",
    "        :param p: Array of transmission probabilities from each of the clients to the PS.\n",
    "        :param A: Matrix of weights\n",
    "        :param P: Matrix of probabilities for intermittent connectivity amongst clients\n",
    "        :param reg_type: Type of regularization\n",
    "        :param reg_strength: Hyperparameter -- weight of regularization term\n",
    "    \"\"\"\n",
    "    \n",
    "    num_clients = len(p)\n",
    "    A_dim = A.shape\n",
    "    neighbors_dim = P.shape\n",
    "    \n",
    "    # Validate inputs\n",
    "    assert num_clients == A_dim[0] == A_dim[1]\n",
    "    assert num_clients == neighbors_dim[0] == neighbors_dim[1]\n",
    "    \n",
    "    if reg_type == \"L2\":\n",
    "        \n",
    "        # Compute the bias terms\n",
    "        bias = torch.zeros(num_clients)\n",
    "        for i in range(num_clients):\n",
    "            for j in range(num_clients):\n",
    "                bias[i] += p[j] * P[i][j] * A[i][j]\n",
    "            bias[i] -= 1\n",
    "            \n",
    "        return reg_strength / 2.0 * torch.norm(bias, 2) ** 2 \n",
    "    \n",
    "    elif reg_type == \"L1\":\n",
    "        \n",
    "        # Compute the bias terms\n",
    "        bias = torch.zeros(num_clients)\n",
    "        for i in range(num_clients):\n",
    "            for j in range(num_clients):\n",
    "                bias[i] += p[j] * P[i][j] * A[i][j]\n",
    "            bias[i] -= 1\n",
    "            \n",
    "        return reg_strength / 2.0 * torch.norm(bias, 1) ** 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192833a-6543-400d-81b6-9b4c087a1aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Torch optimization object\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Custom Pytorch model for gradient optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, p: torch.Tensor = None, P: torch.Tensor = None, \n",
    "                 reg_type: str = \"L2\", reg_strength: torch.Tensor = torch.tensor(0)):\n",
    "        \n",
    "        super().__init__()\n",
    "        num_clients = len(p)\n",
    "        \n",
    "        # Initialize weights with random numbers\n",
    "        weights = torch.distributions.Uniform(0, 0.1).sample((num_clients, num_clients))\n",
    "\n",
    "        # Initial weights are consistent with network topology\n",
    "        weights = torch.where(P > 0, weights, 0)\n",
    "        \n",
    "        # Make weights torch parameters\n",
    "        self.weights = nn.Parameter(weights)        \n",
    "        \n",
    "    def forward(self, p, P, reg_type: str = \"L2\", reg_strength: torch.Tensor = torch.tensor(0)):\n",
    "        \"\"\"Implement the topology induced variance to be optimized\n",
    "        \"\"\"\n",
    "        \n",
    "        A = self.weights\n",
    "        return evaluate_tiv(p, A, P) + evaluate_regularizer(p, A, P, reg_type, reg_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d36dfa-c00d-4f5b-bfc4-17644f774f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clipping to ensure non-negative weights\n",
    "\n",
    "class ZeroClipper(object):\n",
    "    \"\"\"Clip the weights to zero if they are negative\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frequency=1):\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def __call__(self, module):\n",
    "        # filter the variables to get the ones you want\n",
    "        if hasattr(module, 'weights'):\n",
    "            w = module.weights.data\n",
    "            nn.ReLU(inplace=True)(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70f50b-8394-459d-ab92-85c993a16f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimization loop\n",
    "\n",
    "clipper = ZeroClipper()\n",
    "\n",
    "def training_loop(model: nn.Module, optimizer, n: int = 3000):\n",
    "    \"Training loop for torch model.\"\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        loss = model(p, P, reg_type, reg_strength)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if i % clipper.frequency == 0:\n",
    "            model.apply(clipper)\n",
    "            \n",
    "        losses.append(loss) \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration: {i}/{n}\")\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858eb33-3bf1-4b0a-bf0a-3598e09b92a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate model and network topology\n",
    "num_clients = 5\n",
    "p = torch.Tensor([0.5, 0.4, 0.3, 0.8, 0.9])\n",
    "P = 0.2 * torch.ones(num_clients, num_clients)\n",
    "P.fill_diagonal_(1)\n",
    "reg_type = \"L1\"\n",
    "reg_strength = torch.tensor(5)\n",
    "\n",
    "# num_clients = 10\n",
    "# p, P, _ = client_locations_mmWave_clusters_intermittent(num_clients)\n",
    "# print(f\"p = {p}\")\n",
    "# print(f\"P = \\n{P}\")\n",
    "# p = torch.tensor(p)\n",
    "# P = torch.tensor(P)\n",
    "# reg_type = \"L1\"\n",
    "# reg_strength = torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051f316-7cca-4310-aeb5-ab0bb51a4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the optimization\n",
    "\n",
    "m = Model(p, P, reg_type, reg_strength)\n",
    "# Instantiate optimizer\n",
    "opt = torch.optim.Adam(m.parameters(), lr=0.001)\n",
    "losses = training_loop(m, opt)\n",
    "plt.figure(figsize=(14, 7))\n",
    "with torch.no_grad():\n",
    "    plt.plot(losses)\n",
    "\n",
    "print(m.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7686dc-fdc0-4589-a335-6a7bdeaa31fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Final loss: {losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a279876-b96c-41de-8ad0-f33a0ded2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = m.weights.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d21dc-2fba-4ded-92a8-a06725c6b5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(evaluate_tiv(p, W, P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110efd49-25ea-4d70-889e-18825fe0543d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Check biasedness for each node: \\n\")\n",
    "\n",
    "bias = torch.zeros(num_clients)\n",
    "for i in range(num_clients):\n",
    "    for j in range(num_clients):\n",
    "        bias[i] += p[j] * P[i][j] * W[i][j]\n",
    "    bias[i] -= 1\n",
    "    print(f\"Bias at node {i} is {bias[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea2799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ColRel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
